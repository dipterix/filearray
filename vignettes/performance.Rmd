---
title: "Performance Comparisons - (Numerical)"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Performance Comparisons - (Numerical)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  eval = FALSE,
  comment = "#>"
)
```

This vignette profiles `FileArray` operations and compares with R native functions. The goal is to

1. Benchmark different ways to operate on file arrays (write, read, subset, transform, ...)
2. Compare with other methods to see what file array can and cannot do.

The simulation was performed on `MacBook Air 2020 (M1 Chip, ARM, 8GB RAM)`, with R `4.1.0`. To reproduce the results, please install `CRAN` packages `dipsaus` and `microbenchmark`.


## Setup

We mainly test the performance of `double` and `float` data type. The dimensions for both arrays are `100x100x100x100`. Both arrays are around `800MB` in native R. This is because R does not have float precision. However, while `double` array occupies `800MB` space on the hard disk, `float` array only uses half size (`400MB`).

```{r setup}
library(filearray)

options(digits = 3)
filearray_threads()
#> [1] 8

# Create file array and initialize partitions
set.seed(1)
file <- tempfile(); unlink(file, recursive = TRUE)
x_dbl <- filearray_create(file, rep(100, 4))
x_dbl$initialize_partition()

file <- tempfile(); unlink(file, recursive = TRUE)
x_flt <- filearray_create(file, rep(100, 4), type = 'float')
x_flt$initialize_partition()

# 800 MB double array
y <- array(rnorm(length(x_dbl)), dim(x_dbl))
```

## Simulation

The simulation contains

* [Write speed](#write)
  - [Writing along margin](#write-along-margin)
  - [Writing chunks of data](#write-chunks-of-data)
* [Read speed](#read)
  - [Read all the data](#read-the-whole-array)
  - [Read along margins](#read-along-margins)
  - [Random access](#random-access)
* [Collapse](#collapse)

## Write

### 1. Write along margin

Writing along margins refer to something like `x[,,,i] <- v` (along the last margin), or `x[,i,,] <- v` (along the second margin). It is always recommended to write along the last margin, and always discouraged to write along the first margin to file arrays.

1.  partition margin

```{r}
microbenchmark::microbenchmark(
  double = {
    for(i in 1:100){
      x_dbl[,,,i] <- y[,,,i]
    }
  },
  float = {
    for(i in 1:100){
      x_flt[,,,i] <- y[,,,i]
    }
  }, unit = 's', times = 3
)

#> Unit: seconds
#>    expr   min    lq  mean median   uq  max neval
#>  double 1.100 1.117 1.200  1.134 1.25 1.37     3
#>   float 0.799 0.892 0.944  0.984 1.02 1.05     3
```

2. Write along fast margin

```{r}
microbenchmark::microbenchmark(
  double = {
    for(i in 1:100){
      x_dbl[,,i,] <- y[,,i,]
    }
  },
  float = {
    for(i in 1:100){
      x_flt[,,i,] <- y[,,i,]
    }
  }, unit = 's', times = 3
)

#> Unit: seconds
#>    expr  min   lq mean median   uq  max neval
#>  double 1.54 1.59 2.81   1.64 3.44 5.24     3
#>   float 1.32 1.35 1.38   1.37 1.40 1.44     3
```

3. Writing along slow margin

Since it'll take long to run, I only wrote first 10 slices, and multiply by 10 to approximate.

```{r}
system.time({
  for(i in 1:10){
    x_dbl[1,,,] <- y[1,,,]
  }
}) * 10
#>    user  system elapsed 
#>    20.1   312.8    53.9
```


### 2. Write chunks of data

Instead of writing one slice at a time along each margin, we write `100x100x100x5` (10 slices) each time.

1.  partition margin

```{r}
microbenchmark::microbenchmark(
  double = {
    for(i in 1:10){
      idx <- (i-1)*10 + 1:10
      x_dbl[,,,idx] <- y[,,,idx]
    }
  },
  float = {
    for(i in 1:10){
      idx <- (i-1)*10 + 1:10
      x_flt[,,,idx] <- y[,,,idx]
    }
  }, unit = 's', times = 3
)

#> Unit: seconds
#>    expr   min    lq  mean median    uq   max neval
#>  double 1.015 1.052 1.115  1.088 1.165 1.241     3
#>   float 0.716 0.739 0.747  0.763 0.763 0.763     3
```

2. Write along fast margin

```{r}
microbenchmark::microbenchmark(
  double = {
    for(i in 1:10){
      idx <- (i-1)*10 + 1:10
      x_dbl[,,idx,] <- y[,,idx,]
    }
  },
  float = {
    for(i in 1:10){
      idx <- (i-1)*10 + 1:10
      x_flt[,,idx,] <- y[,,idx,]
    }
  }, unit = 's', times = 3
)

#> Unit: seconds
#>    expr   min   lq  mean median    uq   max neval
#>  double 0.991 1.02 1.040  1.049 1.064 1.079     3
#>   float 0.712 0.76 0.778  0.809 0.812 0.814     3
```

3. Writing along slow margin

```{r}
microbenchmark::microbenchmark(
  double = {
    for(i in 1:10){
      idx <- (i-1)*10 + 1:10
      x_dbl[idx,,,] <- y[idx,,,]
    }
  },
  float = {
    for(i in 1:10){
      idx <- (i-1)*10 + 1:10
      x_flt[idx,,,] <- y[idx,,,]
    }
  }, unit = 's', times = 3
)
#> Unit: seconds
#>    expr  min   lq mean median   uq  max neval
#>  double 6.48 6.67 6.94   6.86 7.17 7.48     3
#>   float 3.45 3.78 3.93   4.11 4.17 4.22     3
```

Note: always avoid writing along the first margin (like `x[i,,,] <- ...`). It's slow.



## Read 

### 1. Read the whole array

```{r}
microbenchmark::microbenchmark(
  double = { x_dbl[] },
  float = { x_flt[] },
  unit = 's', times = 3
)

#> Unit: seconds
#>    expr    min     lq  mean median    uq   max neval
#>  double 0.0973 0.0988 0.164 0.1002 0.198 0.296     3
#>   float 0.0893 0.0898 0.133 0.0904 0.155 0.220     3
```

### 2. Read along margins

```{r}
microbenchmark::microbenchmark(
  farr_double_partition_margin = { x_dbl[,,,1] },
  farr_double_fast_margin = { x_dbl[,,1,] },
  farr_double_slow_margin = { x_dbl[1,,,] },
  farr_float_partition_margin = { x_flt[,,,1] },
  farr_float_fast_margin = { x_flt[,,1,] },
  farr_float_slow_margin = { x_flt[1,,,] },
  native_partition_margin = { y[,,,1] },
  native_fast_margin = { y[,,1,] },
  native_slow_margin = { y[1,,,] },
  times = 100L, unit = "ms"
)

#> Unit: milliseconds
#>                          expr   min    lq  mean median    uq   max neval
#>  farr_double_partition_margin  2.97  3.17  4.17   3.39  4.27  31.7   100
#>       farr_double_fast_margin  1.57  1.87  3.22   2.04  3.01  75.7   100
#>       farr_double_slow_margin 22.27 23.88 28.80  24.86 26.56 143.1   100
#>   farr_float_partition_margin  2.65  2.89  4.05   3.05  4.32  33.6   100
#>        farr_float_fast_margin  1.34  1.80  3.73   2.01  2.66  38.6   100
#>        farr_float_slow_margin 13.71 14.61 17.74  15.68 17.61  49.8   100
#>       native_partition_margin  3.74  3.97  4.34   4.09  4.34  10.1   100
#>            native_fast_margin  3.86  3.94  4.35   4.06  4.22  10.0   100
#>            native_slow_margin 21.41 22.13 23.81  22.54 23.68  82.1   100
```

The file array indexing is tied or even faster than native arrays in R!

### 3. Random access

```{r}
# access 50 x 50 x 50 x 50 sub-array, with random indices
idx1 <- sample(1:100, 50)
idx2 <- sample(1:100, 50)
idx3 <- sample(1:100, 50)
idx4 <- sample(1:100, 50)

microbenchmark::microbenchmark(
  farr_double = { x_dbl[idx1, idx2, idx3, idx4] },
  farr_float = { x_flt[idx1, idx2, idx3, idx4] },
  native = { y[idx1, idx2, idx3, idx4] },
  times = 100L, unit = "ms"
)

#> Unit: milliseconds
#>         expr   min   lq mean median   uq  max neval
#>  farr_double 14.47 15.6 18.8   16.5 17.6 99.9   100
#>   farr_float  9.54 10.9 15.8   11.6 12.4 83.0   100
#>       native 33.22 34.3 37.1   35.0 35.6 84.3   100
```

Random access could be faster than base R (also much less memory!)

## Collapse

Collapse calculates the margin sum/mean. Collapse function in `filearray` uses single thread. This is because the bottle-neck often comes from hard-disk accessing speed. However, it is still faster than native R, and is more memory-efficient.

```{r}
keep <- c(2, 4)
microbenchmark::microbenchmark(
  farr_double = { x_dbl$collapse(keep = keep, method = "sum") },
  farr_float = { x_flt$collapse(keep = keep, method = "sum") },
  native = { apply(y, keep, sum) },
  dipsaus = { dipsaus::collapse(y, keep, average = FALSE) }, 
  unit = "s", times = 5
)

#> Unit: seconds
#>         expr   min    lq  mean median    uq   max neval
#>  farr_double 0.679 0.797 0.881  0.815 1.004 1.111     5
#>   farr_float 0.651 0.741 0.795  0.788 0.812 0.981     5
#>       native 1.344 1.391 1.516  1.506 1.659 1.680     5
#>      dipsaus 0.206 0.209 0.233  0.241 0.246 0.264     5
```

The `dipsaus` package uses multiple threads to collapse arrays in-memory. It is `7~8x` as fast as base R. File array is `1.5~2x` as fast as base R. Both `dipsaus` and `filearray` have little memory over-heads.

